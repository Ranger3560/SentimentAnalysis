{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1FiClsm5SfJsbX/zusDyK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ranger3560/SentimentAnalysis/blob/main/XLM_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Corteva Sentiment Analysis using XLM-RoBERTa Fine-tuned Model\n",
        "import csv\n",
        "from transformers import pipeline\n",
        "from datetime import datetime\n",
        "import re\n",
        "\n",
        "# Initialize sentiment analysis pipeline\n",
        "_sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-xlm-roberta-base-sentiment-multilingual\")\n",
        "\n",
        "#Predicts sentiment for the given text and assigns a normalized score based on the predicted label and the user-defined ranges.\n",
        "def predict_sentiment(text: str):\n",
        "    try:\n",
        "        if not text.strip():\n",
        "            # Assign neutral sentiment for empty reviews\n",
        "            return {\"label\": \"NEUTRAL\", \"score\": 0.6} # Default score in neutral range\n",
        "\n",
        "        # Get sentiment analysis result from the pipeline\n",
        "        result = _sentiment_pipeline(text)[0]\n",
        "        raw_label = result['label'].upper()\n",
        "        confidence_score = result['score'] # This is the confidence of the predicted label\n",
        "\n",
        "        # Mapping standard labels (e.g., LABEL_0, LABEL_1, LABEL_2) to standard sentiment names\n",
        "        label_map = {\n",
        "            \"NEGATIVE\": \"NEGATIVE\",\n",
        "            \"NEUTRAL\": \"NEUTRAL\",\n",
        "            \"POSITIVE\": \"POSITIVE\",\n",
        "            \"LABEL_0\": \"NEGATIVE\",\n",
        "            \"LABEL_1\": \"NEUTRAL\",\n",
        "            \"LABEL_2\": \"POSITIVE\"\n",
        "        }\n",
        "        mapped_label = label_map.get(raw_label, raw_label)\n",
        "\n",
        "        # Calculate normalized score based on user requirements\n",
        "\n",
        "        if mapped_label == \"POSITIVE\":\n",
        "            normalized_score = 0.7 + (confidence_score * 0.3)\n",
        "        elif mapped_label == \"NEUTRAL\":\n",
        "            normalized_score = 0.5 + (confidence_score * 0.2)\n",
        "        elif mapped_label == \"NEGATIVE\":\n",
        "            normalized_score = 0.5 - (confidence_score * 0.5)\n",
        "        else:\n",
        "            mapped_label = \"NEUTRAL\"\n",
        "            normalized_score = 0.6\n",
        "\n",
        "        # Ensure the score is within the 0 to 1 range\n",
        "        normalized_score = max(0.0, min(1.0, normalized_score))\n",
        "\n",
        "        return {\"label\": mapped_label, \"score\": normalized_score}\n",
        "    except Exception as e:\n",
        "        print(f\"Error analyzing sentiment for text '{text[:50]}...': {e}\")\n",
        "        return {\"label\": \"ERROR\", \"score\": 0.0}\n",
        "\n",
        "#Loads reviews from the input CSV file.\n",
        "\n",
        "def load_reviews(file_path: str) -> list[dict]:\n",
        "    reviews = []\n",
        "    try:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            reader = csv.DictReader(file)\n",
        "            for row in reader:\n",
        "                reviews.append({\n",
        "                    # Read all specified columns\n",
        "                    \"date\": row.get(\"Date\", \"\"),\n",
        "                    \"verified\": row.get(\"Verified\", \"\"),\n",
        "                    \"product_id\": row.get(\"ProductID\", \"\"),\n",
        "                    \"rating\": row.get(\"Rating\", \"\"),\n",
        "                    \"title\": row.get(\"Title\", \"\"),\n",
        "                    \"review_text\": row.get(\"ReviewText\", \"\"),\n",
        "                    \"review_id\": row.get(\"ReviewID\", \"\")\n",
        "                })\n",
        "        print(f\"Successfully loaded {len(reviews)} reviews from {file_path}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{file_path}' was not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading file '{file_path}': {e}\")\n",
        "    return reviews\n",
        "\n",
        "def analyze_reviews(input_file: str, output_file: str):\n",
        "    reviews = load_reviews(input_file)\n",
        "\n",
        "    if not reviews:\n",
        "        print(f\"No reviews found in {input_file}. Exiting analysis.\")\n",
        "        return\n",
        "\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\", newline=\"\") as outfile:\n",
        "        # Define output columns including SentimentLabel, and SentimentScore\n",
        "        fieldnames = [\n",
        "            \"Date\", \"Verified\", \"ProductID\", \"Rating\", \"Title\",\n",
        "            \"ReviewText\", \"ReviewID\", \"SentimentLabel\", \"SentimentScore\"\n",
        "        ]\n",
        "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "        current_date_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        print(f\"\\n--- Product Review Analysis - Start Time: {current_date_time} ---\\n\")\n",
        "        print(f\"Processing {len(reviews)} reviews...\")\n",
        "\n",
        "        for review in reviews:\n",
        "            # Extract relevant information\n",
        "            text = review.get(\"review_text\", \"\")\n",
        "            rating = review.get(\"rating\", \"\")\n",
        "            verified = review.get(\"verified\", \"\")\n",
        "            product_id = review.get(\"product_id\", \"\")\n",
        "            title = review.get(\"title\", \"\")\n",
        "            review_id = review.get(\"review_id\", \"\")\n",
        "\n",
        "            # Use the existing 'Date' column from the input\n",
        "            date = review.get(\"date\", \"\")\n",
        "\n",
        "            # Basic text cleaning (removing extra whitespace and quotes)\n",
        "            clean_text = ' '.join(text.split()).replace('\"', '')\n",
        "\n",
        "            # Predict sentiment and get normalized score\n",
        "            sentiment_result = predict_sentiment(clean_text)\n",
        "            sentiment_label = sentiment_result[\"label\"]\n",
        "            sentiment_score = sentiment_result[\"score\"]\n",
        "\n",
        "            # Write the results to the output CSV\n",
        "            writer.writerow({\n",
        "                \"Date\": date,\n",
        "                \"ProductID\": product_id,\n",
        "                \"Verified\": verified,\n",
        "                \"Rating\": rating,\n",
        "                \"Title\": title,\n",
        "                \"ReviewText\": text,\n",
        "                \"ReviewID\": review_id,\n",
        "                \"SentimentLabel\": sentiment_label,\n",
        "                \"SentimentScore\": f\"{sentiment_score:.4f}\"\n",
        "            })\n",
        "\n",
        "    print(f\"\\nAnalysis complete. Results saved to '{output_file}'\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_file = \"/content/Corteva_Extrapolated_Dataset.csv\"\n",
        "    output_file = \"XLM_Corteva_Output_Sentiment_Analysis.csv\"\n",
        "    analyze_reviews(input_file, output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4q5AgGk8LV8B",
        "outputId": "6056d316-63ca-440b-d4aa-cddaeb6fcade"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded 1000 reviews from /content/Corteva_Extrapolated_Dataset.csv\n",
            "\n",
            "--- Product Review Analysis - Start Time: 2025-07-12 12:11:59 ---\n",
            "\n",
            "Processing 1000 reviews...\n",
            "\n",
            "Analysis complete. Results saved to 'XLM_Corteva_Output_Sentiment_Analysis.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Syngenta Sentiment Analysis using XLM-RoBERTa Fine-tuned Model\n",
        "import csv\n",
        "from transformers import pipeline\n",
        "from datetime import datetime\n",
        "import re\n",
        "\n",
        "# Initialize sentiment analysis pipeline\n",
        "_sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-xlm-roberta-base-sentiment-multilingual\")\n",
        "\n",
        "#Predicts sentiment for the given text and assigns a normalized score based on the predicted label and the user-defined ranges.\n",
        "def predict_sentiment(text: str):\n",
        "    try:\n",
        "        if not text.strip():\n",
        "            # Assign neutral sentiment for empty reviews\n",
        "            return {\"label\": \"NEUTRAL\", \"score\": 0.6} # Default score in neutral range\n",
        "\n",
        "        # Get sentiment analysis result from the pipeline\n",
        "        result = _sentiment_pipeline(text)[0]\n",
        "        raw_label = result['label'].upper()\n",
        "        confidence_score = result['score'] # This is the confidence of the predicted label\n",
        "\n",
        "        # Mapping standard labels (e.g., LABEL_0, LABEL_1, LABEL_2) to standard sentiment names\n",
        "        label_map = {\n",
        "            \"NEGATIVE\": \"NEGATIVE\",\n",
        "            \"NEUTRAL\": \"NEUTRAL\",\n",
        "            \"POSITIVE\": \"POSITIVE\",\n",
        "            \"LABEL_0\": \"NEGATIVE\",\n",
        "            \"LABEL_1\": \"NEUTRAL\",\n",
        "            \"LABEL_2\": \"POSITIVE\"\n",
        "        }\n",
        "        mapped_label = label_map.get(raw_label, raw_label)\n",
        "\n",
        "        # Calculate normalized score based on user requirements\n",
        "\n",
        "        if mapped_label == \"POSITIVE\":\n",
        "            normalized_score = 0.7 + (confidence_score * 0.3)\n",
        "        elif mapped_label == \"NEUTRAL\":\n",
        "            normalized_score = 0.5 + (confidence_score * 0.2)\n",
        "        elif mapped_label == \"NEGATIVE\":\n",
        "            normalized_score = 0.5 - (confidence_score * 0.5)\n",
        "        else:\n",
        "            mapped_label = \"NEUTRAL\"\n",
        "            normalized_score = 0.6\n",
        "\n",
        "        # Ensure the score is within the 0 to 1 range\n",
        "        normalized_score = max(0.0, min(1.0, normalized_score))\n",
        "\n",
        "        return {\"label\": mapped_label, \"score\": normalized_score}\n",
        "    except Exception as e:\n",
        "        print(f\"Error analyzing sentiment for text '{text[:50]}...': {e}\")\n",
        "        return {\"label\": \"ERROR\", \"score\": 0.0}\n",
        "\n",
        "#Loads reviews from the input CSV file.\n",
        "\n",
        "def load_reviews(file_path: str) -> list[dict]:\n",
        "    reviews = []\n",
        "    try:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            reader = csv.DictReader(file)\n",
        "            for row in reader:\n",
        "                reviews.append({\n",
        "                    # Read all specified columns\n",
        "                    \"date\": row.get(\"Date\", \"\"),\n",
        "                    \"verified\": row.get(\"Verified\", \"\"),\n",
        "                    \"product_id\": row.get(\"ProductID\", \"\"),\n",
        "                    \"rating\": row.get(\"Rating\", \"\"),\n",
        "                    \"title\": row.get(\"Title\", \"\"),\n",
        "                    \"review_text\": row.get(\"ReviewText\", \"\"),\n",
        "                    \"review_id\": row.get(\"ReviewID\", \"\")\n",
        "                })\n",
        "        print(f\"Successfully loaded {len(reviews)} reviews from {file_path}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{file_path}' was not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading file '{file_path}': {e}\")\n",
        "    return reviews\n",
        "\n",
        "def analyze_reviews(input_file: str, output_file: str):\n",
        "    reviews = load_reviews(input_file)\n",
        "\n",
        "    if not reviews:\n",
        "        print(f\"No reviews found in {input_file}. Exiting analysis.\")\n",
        "        return\n",
        "\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\", newline=\"\") as outfile:\n",
        "        # Define output columns including SentimentLabel, and SentimentScore\n",
        "        fieldnames = [\n",
        "            \"Date\", \"Verified\", \"ProductID\", \"Rating\", \"Title\",\n",
        "            \"ReviewText\", \"ReviewID\", \"SentimentLabel\", \"SentimentScore\"\n",
        "        ]\n",
        "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "        current_date_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        print(f\"\\n--- Product Review Analysis - Start Time: {current_date_time} ---\\n\")\n",
        "        print(f\"Processing {len(reviews)} reviews...\")\n",
        "\n",
        "        for review in reviews:\n",
        "            # Extract relevant information\n",
        "            text = review.get(\"review_text\", \"\")\n",
        "            rating = review.get(\"rating\", \"\")\n",
        "            verified = review.get(\"verified\", \"\")\n",
        "            product_id = review.get(\"product_id\", \"\")\n",
        "            title = review.get(\"title\", \"\")\n",
        "            review_id = review.get(\"review_id\", \"\")\n",
        "\n",
        "            # Use the existing 'Date' column from the input\n",
        "            date = review.get(\"date\", \"\")\n",
        "\n",
        "            # Basic text cleaning (removing extra whitespace and quotes)\n",
        "            clean_text = ' '.join(text.split()).replace('\"', '')\n",
        "\n",
        "            # Predict sentiment and get normalized score\n",
        "            sentiment_result = predict_sentiment(clean_text)\n",
        "            sentiment_label = sentiment_result[\"label\"]\n",
        "            sentiment_score = sentiment_result[\"score\"]\n",
        "\n",
        "            # Write the results to the output CSV\n",
        "            writer.writerow({\n",
        "                \"Date\": date,\n",
        "                \"ProductID\": product_id,\n",
        "                \"Verified\": verified,\n",
        "                \"Rating\": rating,\n",
        "                \"Title\": title,\n",
        "                \"ReviewText\": text,\n",
        "                \"ReviewID\": review_id,\n",
        "                \"SentimentLabel\": sentiment_label,\n",
        "                \"SentimentScore\": f\"{sentiment_score:.4f}\"\n",
        "            })\n",
        "\n",
        "    print(f\"\\nAnalysis complete. Results saved to '{output_file}'\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_file = \"/content/Syngenta_Extrapolated_Dataset.csv\"\n",
        "    output_file = \"XLM_Syngenta_Output_Sentiment_Analysis.csv\"\n",
        "    analyze_reviews(input_file, output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ii40Tdca76Yo",
        "outputId": "7d75b6f4-2fed-41a6-de28-2b59b8f96ac0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded 1000 reviews from /content/Syngenta_Extrapolated_Dataset.csv\n",
            "\n",
            "--- Product Review Analysis - Start Time: 2025-07-12 12:21:41 ---\n",
            "\n",
            "Processing 1000 reviews...\n",
            "\n",
            "Analysis complete. Results saved to 'XLM_Syngenta_Output_Sentiment_Analysis.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eUaNeX991y0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UH0-cQ2P1y2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-v7qcbbK1zIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aybRa_Z-1zVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zn1Pxgud1zbW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}